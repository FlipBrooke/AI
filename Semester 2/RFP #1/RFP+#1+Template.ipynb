{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b940825",
   "metadata": {},
   "source": [
    "# RFP: Betting on the Bachelor\n",
    "\n",
    "## Project Overview\n",
    "You are invited to submit a proposal that answers the following question:\n",
    "\n",
    "### Who will win season 29 of the Bachelor?\n",
    "\n",
    "*All proposals must be submitted by **1/15/25 at 11:59 PM**.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "968a85f0",
   "metadata": {},
   "source": [
    "## Required Proposal Components\n",
    "\n",
    "### 1. Data Description\n",
    "In the code cell below, read in the data you plan on using to train and test your model. Call `info()` once you have read the data into a dataframe. Consider using some or all of the following sources:\n",
    "- [Scrape Fandom Wikis](https://bachelor-nation.fandom.com/wiki/The_Bachelor) or [the official Bachelor website]('https://bachelornation.com/shows/the-bachelor/')\n",
    "- [Ask ChatGPT to genereate it](https://chatgpt.com/)\n",
    "- [Read in csv files like this](https://www.kaggle.com/datasets/brianbgonz/the-bachelor-contestants?select=contestants.csv)\n",
    "\n",
    "*Note, a level 5 dataset contains at least 1000 rows of non-null data. A level 4 contains at least 500 rows of non-null data.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08c1688a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "# Function to scrape contestant data from a season page\n",
    "def scrape_contestants_from_season(url):\n",
    "    # Make a request and follow any redirects\n",
    "    response = requests.get(url)\n",
    "    \n",
    "    # Check if the URL is redirecting to the episode list page\n",
    "    if \"List_of_The_Bachelor_(American_TV_series)_episodes\" in response.url:\n",
    "        print(f\"Skipping season {url}: Redirects to the episodes list page.\")\n",
    "        return None\n",
    "\n",
    "    # Parse the page content\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "    # Find the contestant table by class\n",
    "    table = soup.find('table', {'class': 'wikitable'})\n",
    "\n",
    "    if not table:\n",
    "        print(f\"Skipping season {url}: No contestant table found.\")\n",
    "        return None\n",
    "\n",
    "    # Initialize a list to store contestant data\n",
    "    contestants = []\n",
    "\n",
    "    # Iterate over each row of the table, skipping the header row\n",
    "    for row in table.find_all('tr')[1:]:\n",
    "        cols = row.find_all('td')\n",
    "\n",
    "        # Make sure there are enough columns (check length)\n",
    "        if len(cols) >= 5:\n",
    "            name = cols[0].get_text(strip=True)\n",
    "            age = cols[1].get_text(strip=True)\n",
    "            hometown = cols[2].get_text(strip=True)\n",
    "            occupation = cols[3].get_text(strip=True)\n",
    "            outcome = cols[4].get_text(strip=True)\n",
    "\n",
    "            contestants.append([name, age, hometown, occupation, outcome])\n",
    "\n",
    "    return contestants\n",
    "\n",
    "# Function to scrape multiple seasons and store the data in a DataFrame\n",
    "def scrape_bachelor_seasons(start_season, end_season):\n",
    "    # Create an empty list to hold all the data\n",
    "    all_contestants = []\n",
    "\n",
    "    # Iterate over the seasons and scrape the data\n",
    "    for season in range(start_season, end_season + 1):\n",
    "        season_url = f\"https://en.wikipedia.org/wiki/The_Bachelor_(American_TV_series)_season_{season}\"\n",
    "        print(f\"Scraping season {season}...\")\n",
    "\n",
    "        contestants = scrape_contestants_from_season(season_url)\n",
    "\n",
    "        if contestants:  # Only add to the list if there are contestants\n",
    "            for contestant in contestants:\n",
    "                all_contestants.append([season] + contestant)\n",
    "        else:\n",
    "            print(f\"Skipping season {season}: No contestants found or redirected to episode list.\")\n",
    "\n",
    "    # Create a DataFrame from the collected data\n",
    "    df = pd.DataFrame(all_contestants, columns=['Season', 'Name', 'Age', 'Hometown', 'Occupation', 'Outcome'])\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Scrape seasons 1 to the latest season (adjust season range as necessary)\n",
    "df = scrape_bachelor_seasons(1, 28)\n",
    "\n",
    "# Optionally, save the DataFrame to a CSV file\n",
    "df.to_csv('bachelor_contestants.csv', index=False)\n",
    "\n",
    "# Show the DataFrame\n",
    "print(df.head())  # Print the first few rows of the DataFrame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "911892ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "880ff05f",
   "metadata": {},
   "source": [
    "### 2. Training Your Model\n",
    "In the cell seen below, write the code you need to train a linear regression model. Make sure you display the equation of the plane that best fits your chosen data at the end of your program. \n",
    "\n",
    "*Note, level 5 work trains a model using only the standard Python library and Pandas. A level 5 model is trained with at least two features, where one of the features begins as a categorical value (e.g. occupation, hometown, etc.). A level 4 uses external libraries like scikit or numpy.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a87a9144",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model here.\n",
    "# Don't forget to display the equation of the plane that best fits your data!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfb2b903",
   "metadata": {},
   "source": [
    "### 3. Testing Your Model\n",
    "In the cell seen below, write the code you need to test your linear regression model. \n",
    "\n",
    "*Note, a model is considered a level 5 if it achieves at least 60% prediction accuracy or achieves an RMSE of 2 weeks or less.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "24f8b990",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test model here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "343eb3f7",
   "metadata": {},
   "source": [
    "### 4. Final Answer\n",
    "\n",
    "In the first cell seen below, state the name of your predicted winner. \n",
    "In the second cell seen below, justify your prediction using an evaluation technique like RMSE or percent accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25533722",
   "metadata": {},
   "source": [
    "#### State the name of your predicted winner here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e29adde2",
   "metadata": {},
   "source": [
    "#### Justify your prediction here."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b940825",
   "metadata": {},
   "source": [
    "# RFP: Betting on the Bachelor\n",
    "\n",
    "## Project Overview\n",
    "You are invited to submit a proposal that answers the following question:\n",
    "\n",
    "### Who will win season 29 of the Bachelor?\n",
    "\n",
    "*All proposals must be submitted by **1/15/25 at 11:59 PM**.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "968a85f0",
   "metadata": {},
   "source": [
    "## Required Proposal Components\n",
    "\n",
    "### 1. Data Description\n",
    "In the code cell below, read in the data you plan on using to train and test your model. Call `info()` once you have read the data into a dataframe. Consider using some or all of the following sources:\n",
    "- [Scrape Fandom Wikis](https://bachelor-nation.fandom.com/wiki/The_Bachelor) or [the official Bachelor website]('https://bachelornation.com/shows/the-bachelor/')\n",
    "- [Ask ChatGPT to genereate it](https://chatgpt.com/)\n",
    "- [Read in csv files like this](https://www.kaggle.com/datasets/brianbgonz/the-bachelor-contestants?select=contestants.csv)\n",
    "\n",
    "*Note, a level 5 dataset contains at least 1000 rows of non-null data. A level 4 contains at least 500 rows of non-null data.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "08c1688a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Season          Name   Age                   Hometown  \\\n",
      "0       1   Alex Michel  31.0  Charlottesville, Virginia   \n",
      "1       2  Aaron Buerge  28.0           Butler, Missouri   \n",
      "2       3           NaN   NaN                        NaN   \n",
      "3       4           NaN   NaN                        NaN   \n",
      "4       5  Jesse Palmer  25.0            Nepean, Ontario   \n",
      "\n",
      "              Occupation  \n",
      "0  management consultant  \n",
      "1                 Banker  \n",
      "2                    NaN  \n",
      "3                    NaN  \n",
      "4        Football Player  \n",
      "   Season               Name   Age               Hometown  \\\n",
      "0       1        Trista Rehn  29.0  Indianapolis, Indiana   \n",
      "1       2  Meredith Phillips  28.0      Beaverton, Oregon   \n",
      "2       3   Jennifer Schefft  28.0           Mentor, Ohio   \n",
      "3       4      DeAnna Pappas  26.0        Newnan, Georgia   \n",
      "4       5     Jillian Harris  29.0   Peace River, Alberta   \n",
      "\n",
      "                     Occupation  \n",
      "0  pediatric physical therapist  \n",
      "1                 Makeup artist  \n",
      "2                     publicist  \n",
      "3             real estate agent  \n",
      "4             interior designer  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping Bachelor Seasons: 100%|████████████████████████████████████| 29/29 [00:06<00:00,  4.55it/s]\n",
      "Scraping Bachelorette Seasons: 100%|████████████████████████████████| 21/21 [00:05<00:00,  4.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Season             Name   Age              Hometown  \\\n",
      "0       1     Amanda Marsh  23.0       Chanute, Kansas   \n",
      "1       1      Trista Rehn  29.0   St. Louis, Missouri   \n",
      "2       1   Shannon Oliver  24.0         Dallas, Texas   \n",
      "3       1  Kimberly Karels  24.0        Tempe, Arizona   \n",
      "4       1     Cathy Grimes  22.0  Terre Haute, Indiana   \n",
      "\n",
      "                        Occupation    Outcome  Place  Score  Age Difference  \\\n",
      "0                    Event Planner     Winner    1.0    1.0             8.0   \n",
      "1                Miami Heat Dancer  Runner-up    NaN    NaN             2.0   \n",
      "2  Financial Management Consultant     Week 5    5.0    3.0             7.0   \n",
      "3                            Nanny     Week 4    4.0    4.0             7.0   \n",
      "4                 Graduate Student     Week 3    3.0    5.0             9.0   \n",
      "\n",
      "  Bachelor Name      Show  \n",
      "0       Unknown  Bachelor  \n",
      "1       Unknown  Bachelor  \n",
      "2       Unknown  Bachelor  \n",
      "3       Unknown  Bachelor  \n",
      "4       Unknown  Bachelor  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Mapping of week number to place\n",
    "week_to_place = {\n",
    "    1: 23, 2: 20, 3: 18, 4: 13, 5: 11, 6: 7, 7: 5, 8: 4, 9: 3, 10: 2\n",
    "}\n",
    "\n",
    "# Define a function to assign scores based on the place and outcome\n",
    "def calculate_score(place, outcome):\n",
    "    # If the outcome contains \"Winner\", the score should always be 1\n",
    "    score_map = {\n",
    "        1: 1,  # Winner (score 1)\n",
    "        2: 2,  # Runner-up (score 2)\n",
    "        3: 5,  # Highest week of season (score 5)\n",
    "        4: 4,  # Highest week -1 (score 4)\n",
    "        5: 3,  # Highest week -2 (score 3)\n",
    "        6: 2,  # Highest week -3 (score 2)\n",
    "        7: 1,  # Highest week -4 to -6 (score 1)\n",
    "    }\n",
    "    return score_map.get(place, 0)  # Default score if not in the map\n",
    "\n",
    "def calculate_place(week_num, outcome):\n",
    "    # Handling specific cases for \"Winner\" and \"Runner-up\" outcomes\n",
    "    if \"Winner\" in outcome:\n",
    "        return 1  # Winner\n",
    "    elif \"Runner-up\" in outcome or \"Runner Up\" in outcome:\n",
    "        return 2  # Runner-up or Runner Up\n",
    "    elif week_num == 1:\n",
    "        return 1  # Winner\n",
    "    elif week_num == 2:\n",
    "        return 2  # Highest week of season\n",
    "    elif week_num == 3:\n",
    "        return 3  # -1 from highest week\n",
    "    elif week_num == 4:\n",
    "        return 4  # -2 from highest week\n",
    "    elif 5 <= week_num <= 8:\n",
    "        return 5  # -3 from highest week (Place 5-8)\n",
    "    elif 9 <= week_num <= 15:\n",
    "        return 6  # -4 to -6 from highest week (Place 9-15)\n",
    "    else:\n",
    "        return 7  # Anything lower (Place 16-25)\n",
    "\n",
    "def scrape_contestants_from_season(url, bachelor_age, show_type):\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        table = soup.find('table', {'class': 'wikitable'})\n",
    "        if not table:\n",
    "            return None\n",
    "        bachelor_name = soup.find('span', {'class': 'bachelor_name'}).get_text(strip=True) if soup.find('span', {'class': 'bachelor_name'}) else 'Unknown'\n",
    "        contestants = []\n",
    "        for row in table.find_all('tr')[1:]:\n",
    "            cols = row.find_all('td')\n",
    "            if len(cols) >= 5:\n",
    "                name, age, hometown, occupation, outcome = [col.get_text(strip=True) for col in cols[:5]]\n",
    "                outcome = re.sub(r'\\(Week \\d+\\)', '', re.sub(r'\\(quit\\)', '', outcome))\n",
    "                week_num = re.search(r'Week (\\d+)', outcome)\n",
    "                \n",
    "                # Initialize place and score with default values\n",
    "                place = np.nan\n",
    "                score = np.nan\n",
    "                \n",
    "                if week_num:\n",
    "                    week_num = int(week_num.group(1))\n",
    "                    place = calculate_place(week_num, outcome)  # Calculate place based on week number\n",
    "                    score = calculate_score(place, outcome)  # Calculate score based on place\n",
    "                \n",
    "                # If \"Winner\" is in the outcome, force score to 1\n",
    "                if \"Winner\" in outcome:\n",
    "                    score = 1\n",
    "                    place = 1  # Force place to 1 for Winner\n",
    "                \n",
    "                # Ensure place and score are assigned correctly\n",
    "                try:\n",
    "                    bachelor_age_int, contestant_age_int = int(bachelor_age), int(age)\n",
    "                    age_difference = bachelor_age_int - contestant_age_int\n",
    "                except ValueError:\n",
    "                    age_difference = None\n",
    "                \n",
    "                contestants.append([name, age, hometown, occupation, outcome, place, score, age_difference, bachelor_name, show_type])\n",
    "        return contestants\n",
    "    except requests.RequestException:\n",
    "        return None\n",
    "\n",
    "def scrape_seasons(start_season, end_season, skip_seasons=[], bachelor_ages_df=None, bachelorette_ages_df=None, show_type=\"Bachelor\"):\n",
    "    all_contestants = []\n",
    "    for season in tqdm(range(start_season, end_season + 1), desc=f\"Scraping {show_type} Seasons\", ncols=100):\n",
    "        if season in skip_seasons:\n",
    "            continue\n",
    "        season_url = f\"https://en.wikipedia.org/wiki/The_{show_type}_(American_TV_series)_season_{season}\"\n",
    "        bachelor_age = 'Unknown'\n",
    "        if show_type == \"Bachelor\" and bachelor_ages_df is not None and not bachelor_ages_df.empty:\n",
    "            bachelor_age = bachelor_ages_df.loc[bachelor_ages_df['Season'] == season, 'Age'].values[0]\n",
    "        elif show_type == \"Bachelorette\" and bachelorette_ages_df is not None and not bachelorette_ages_df.empty:\n",
    "            season_data = bachelorette_ages_df.loc[bachelorette_ages_df['Season'] == season, 'Age']\n",
    "            if not season_data.empty:\n",
    "                bachelor_age = season_data.values[0]\n",
    "            else:\n",
    "                bachelor_age = 'Unknown'\n",
    "        contestants = scrape_contestants_from_season(season_url, bachelor_age, show_type)\n",
    "        if contestants:\n",
    "            all_contestants.extend([[season] + contestant for contestant in contestants])\n",
    "    df = pd.DataFrame(all_contestants, columns=['Season', 'Name', 'Age', 'Hometown', 'Occupation', 'Outcome', 'Place', 'Score', 'Age Difference', 'Bachelor Name', 'Show'])\n",
    "    df['Age'] = pd.to_numeric(df['Age'], errors='coerce')\n",
    "    return df\n",
    "\n",
    "# Load the CSV files for Bachelor and Bachelorette ages\n",
    "bachelor_ages_df = pd.read_csv('Bachelors.csv')\n",
    "bachelorette_ages_df = pd.read_csv('Bachelorettes.csv')\n",
    "\n",
    "# Check if the CSV files were loaded successfully\n",
    "if bachelor_ages_df is None or bachelorette_ages_df is None:\n",
    "    print(\"Error loading CSV files!\")\n",
    "else:\n",
    "    print(bachelor_ages_df.head())\n",
    "    print(bachelorette_ages_df.head())\n",
    "\n",
    "# Scrape the seasons for Bachelor and Bachelorette\n",
    "df_bachelor = scrape_seasons(1, 29, skip_seasons=[3, 4, 6, 7, 8], bachelor_ages_df=bachelor_ages_df, show_type=\"Bachelor\")\n",
    "df_bachelorette = scrape_seasons(1, 21, skip_seasons=[16, 19], bachelorette_ages_df=bachelorette_ages_df, show_type=\"Bachelorette\")\n",
    "\n",
    "# Combine the data for Bachelor and Bachelorette\n",
    "df_combined = pd.concat([df_bachelor, df_bachelorette], ignore_index=True)\n",
    "\n",
    "# Save the combined data to a CSV file\n",
    "df_combined.to_csv('contestants_combined.csv', index=False)\n",
    "\n",
    "# Print the first few rows of the combined data\n",
    "print(df_combined.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "78b7eaf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X is ready for training!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "df_cleaned = pd.read_csv('cleaned_contestants.csv')\n",
    "\n",
    "# Remove any non-letter characters (except spaces) from the 'Name' field\n",
    "df_cleaned['Name'] = df_cleaned['Name'].str.replace(r'[^a-zA-Z ]', '', regex=True)\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "df_cleaned['Hometown'] = label_encoder.fit_transform(df_cleaned['Hometown'].fillna('Unknown'))\n",
    "df_cleaned['Occupation'] = label_encoder.fit_transform(df_cleaned['Occupation'].fillna('Unknown'))\n",
    "\n",
    "X = df_cleaned[['Age', 'Hometown', 'Occupation', 'Age Difference']].copy()\n",
    "\n",
    "X['Age'] = X['Age'].fillna(X['Age'].median())\n",
    "X['Age Difference'] = X['Age Difference'].fillna(X['Age Difference'].median())\n",
    "\n",
    "X.replace([float('inf'), -float('inf')], float('nan'), inplace=True)\n",
    "X.fillna(X.median(), inplace=True)\n",
    "\n",
    "assert not X.isnull().any().any(), \"There are still NaN values in the features.\"\n",
    "assert not (X == float('inf')).any().any() and not (X == -float('inf')).any().any(), \"There are still infinite values in the features.\"\n",
    "\n",
    "# Save the cleaned data back to 'cleaned_contestants.csv'\n",
    "df_cleaned.to_csv('cleaned_contestants.csv', index=False)\n",
    "\n",
    "print(\"X is ready for training!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "880ff05f",
   "metadata": {},
   "source": [
    "### 2. Training Your Model\n",
    "In the cell seen below, write the code you need to train a linear regression model. Make sure you display the equation of the plane that best fits your chosen data at the end of your program. \n",
    "\n",
    "*Note, level 5 work trains a model using only the standard Python library and Pandas. A level 5 model is trained with at least two features, where one of the features begins as a categorical value (e.g. occupation, hometown, etc.). A level 4 uses external libraries like scikit or numpy.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a87a9144",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.09\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.29      0.33      0.31        12\n",
      "         2.0       0.00      0.00      0.00         9\n",
      "         3.0       0.14      0.17      0.15         6\n",
      "         4.0       0.20      0.14      0.17         7\n",
      "         5.0       0.25      0.12      0.17         8\n",
      "         6.0       0.00      0.00      0.00         4\n",
      "         7.0       0.13      0.22      0.17         9\n",
      "         8.0       0.00      0.00      0.00         3\n",
      "         9.0       0.00      0.00      0.00         4\n",
      "        10.0       0.00      0.00      0.00         1\n",
      "        11.0       0.00      0.00      0.00         9\n",
      "        12.0       0.00      0.00      0.00         2\n",
      "        13.0       0.00      0.00      0.00         9\n",
      "        14.0       0.00      0.00      0.00         1\n",
      "        15.0       0.00      0.00      0.00         2\n",
      "        16.0       0.00      0.00      0.00         1\n",
      "        17.0       0.00      0.00      0.00         1\n",
      "        18.0       0.11      0.09      0.10        11\n",
      "        19.0       0.00      0.00      0.00         1\n",
      "        20.0       0.07      0.09      0.08        11\n",
      "        22.0       1.00      0.00      0.00         1\n",
      "        23.0       0.12      0.05      0.07        19\n",
      "        25.0       0.00      0.00      0.00         1\n",
      "        30.0       1.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.09       133\n",
      "   macro avg       0.14      0.05      0.05       133\n",
      "weighted avg       0.11      0.09      0.09       133\n",
      "\n",
      "Confusion Matrix:\n",
      "[[4 0 2 0 0 2 0 1 0 1 0 1 0 0 1 0 0 0 0 0 0 0 0 0]\n",
      " [1 0 0 0 1 1 0 2 0 0 0 1 1 0 1 0 0 0 0 0 0 1 0 0]\n",
      " [0 0 1 1 1 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0]\n",
      " [0 1 0 1 0 1 0 0 0 0 0 1 0 0 0 1 0 0 0 1 0 1 0 0]\n",
      " [2 0 0 0 1 0 0 0 0 0 0 0 2 0 0 0 0 2 0 1 0 0 0 0]\n",
      " [0 0 0 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0]\n",
      " [2 1 0 0 0 0 2 0 0 0 1 0 0 0 0 0 0 1 0 1 0 1 0 0]\n",
      " [0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0]\n",
      " [0 0 1 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 2 0 1 0 2 0 1 0 0 0 2 0 0 0 0 0 0 1 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0]\n",
      " [0 1 1 0 0 0 1 0 1 0 0 0 0 0 1 0 0 0 1 2 0 1 0 0]\n",
      " [0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 2 0 0 0 0 3 1 0 0 0 0 0 0 0 0 0 1 0 3 0 1 0 0]\n",
      " [0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [1 1 0 0 0 0 3 0 0 1 0 0 1 1 0 0 0 1 0 1 0 0 1 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0]\n",
      " [2 1 0 0 0 1 2 1 1 0 2 0 1 0 1 2 0 2 0 2 0 1 0 0]\n",
      " [0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "df_cleaned = pd.read_csv('cleaned_contestants.csv')\n",
    "\n",
    "df_cleaned['Place'].fillna(df_cleaned['Place'].mode()[0], inplace=True)\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "for col in ['Hometown', 'Occupation']:\n",
    "    df_cleaned[col] = label_encoder.fit_transform(df_cleaned[col].astype(str).fillna('Unknown'))\n",
    "\n",
    "for col in ['Age', 'Age Difference']:\n",
    "    df_cleaned[col] = pd.to_numeric(df_cleaned[col], errors='coerce')\n",
    "    df_cleaned[col].fillna(df_cleaned[col].median(), inplace=True)\n",
    "\n",
    "class_counts = df_cleaned['Place'].value_counts()\n",
    "valid_classes = class_counts[class_counts > 1].index\n",
    "df_cleaned_filtered = df_cleaned[df_cleaned['Place'].isin(valid_classes)]\n",
    "\n",
    "X = df_cleaned_filtered[['Age', 'Hometown', 'Occupation', 'Age Difference']]\n",
    "y = df_cleaned_filtered['Place']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "class_weights = dict(enumerate(pd.Series(y_train).value_counts(normalize=True).to_dict()))\n",
    "model = RandomForestClassifier(n_estimators=200, random_state=42, max_depth=15, min_samples_split=5, class_weight='balanced')\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.2f}\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred, zero_division=1))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfb2b903",
   "metadata": {},
   "source": [
    "### 3. Testing Your Model\n",
    "In the cell seen below, write the code you need to test your linear regression model. \n",
    "\n",
    "*Note, a model is considered a level 5 if it achieves at least 60% prediction accuracy or achieves an RMSE of 2 weeks or less.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "24f8b990",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "y contains previously unseen labels: '475'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\_encode.py\u001b[0m in \u001b[0;36m_encode\u001b[1;34m(values, uniques, check_unknown)\u001b[0m\n\u001b[0;32m    181\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 182\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0m_map_to_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muniques\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    183\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\_encode.py\u001b[0m in \u001b[0;36m_map_to_integer\u001b[1;34m(values, uniques)\u001b[0m\n\u001b[0;32m    125\u001b[0m     \u001b[0mtable\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_nandict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mval\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 126\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtable\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    127\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\_encode.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    125\u001b[0m     \u001b[0mtable\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_nandict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mval\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 126\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtable\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    127\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\_encode.py\u001b[0m in \u001b[0;36m__missing__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    119\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnan_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 120\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    121\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: '475'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_14820\\1708303471.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[1;31m# Preprocess Season 29 data (same steps as above)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[1;31m# Fit the LabelEncoder on the 'Hometown' and 'Occupation' columns for the new data (using the training encoder)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 50\u001b[1;33m \u001b[0mseason_29_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Hometown'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlabel_encoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseason_29_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Hometown'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Unknown'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     51\u001b[0m \u001b[0mseason_29_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Occupation'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlabel_encoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseason_29_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Occupation'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Unknown'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_label.py\u001b[0m in \u001b[0;36mtransform\u001b[1;34m(self, y)\u001b[0m\n\u001b[0;32m    136\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    137\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 138\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_encode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muniques\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    139\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0minverse_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\_encode.py\u001b[0m in \u001b[0;36m_encode\u001b[1;34m(values, uniques, check_unknown)\u001b[0m\n\u001b[0;32m    182\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0m_map_to_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muniques\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    183\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 184\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"y contains previously unseen labels: {str(e)}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    185\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    186\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcheck_unknown\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: y contains previously unseen labels: '475'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Load cleaned dataset\n",
    "df_cleaned = pd.read_csv('cleaned_contestants.csv')\n",
    "\n",
    "# Preprocessing as before\n",
    "df_cleaned['Place'].fillna(df_cleaned['Place'].mode()[0], inplace=True)\n",
    "\n",
    "# Initialize LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "place_encoder = LabelEncoder()\n",
    "\n",
    "# Fit the encoder on 'Place', 'Hometown', and 'Occupation' from the training data\n",
    "df_cleaned['Place'] = place_encoder.fit_transform(df_cleaned['Place'].astype(str))\n",
    "df_cleaned['Hometown'] = label_encoder.fit_transform(df_cleaned['Hometown'].astype(str).fillna('Unknown'))\n",
    "df_cleaned['Occupation'] = label_encoder.fit_transform(df_cleaned['Occupation'].astype(str).fillna('Unknown'))\n",
    "\n",
    "# Handle Age and Age Difference\n",
    "for col in ['Age', 'Age Difference']:\n",
    "    df_cleaned[col] = pd.to_numeric(df_cleaned[col], errors='coerce')\n",
    "    df_cleaned[col].fillna(df_cleaned[col].median(), inplace=True)\n",
    "\n",
    "# Filter classes based on valid counts in 'Place'\n",
    "class_counts = df_cleaned['Place'].value_counts()\n",
    "valid_classes = class_counts[class_counts > 1].index\n",
    "df_cleaned_filtered = df_cleaned[df_cleaned['Place'].isin(valid_classes)]\n",
    "\n",
    "# Features and target (exclude 'Place' for prediction)\n",
    "X = df_cleaned_filtered[['Age', 'Hometown', 'Occupation', 'Age Difference']]\n",
    "y = df_cleaned_filtered['Place']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Train the model\n",
    "model = RandomForestClassifier(n_estimators=200, random_state=42, max_depth=15, min_samples_split=5, class_weight='balanced')\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# For Season 29, load the data\n",
    "season_29_data = pd.read_csv('cleaned_contestants.csv')\n",
    "\n",
    "# Filter data for Season 29 and 'Bachelor' Show\n",
    "season_29_data = season_29_data[(season_29_data['Season'] == 29) & (season_29_data['Show'] == 'Bachelor')]\n",
    "\n",
    "# Preprocess Season 29 data (same steps as above)\n",
    "# Fit the LabelEncoder on the 'Hometown' and 'Occupation' columns for the new data (using the training encoder)\n",
    "season_29_data['Hometown'] = label_encoder.transform(season_29_data['Hometown'].astype(str).fillna('Unknown'))\n",
    "season_29_data['Occupation'] = label_encoder.transform(season_29_data['Occupation'].astype(str).fillna('Unknown'))\n",
    "\n",
    "# For unseen labels in Season 29, apply a default encoding\n",
    "season_29_data['Hometown'] = season_29_data['Hometown'].apply(lambda x: x if x in label_encoder.classes_ else -1)  # Assigning -1 for unseen\n",
    "season_29_data['Occupation'] = season_29_data['Occupation'].apply(lambda x: x if x in label_encoder.classes_ else -1)  # Assigning -1 for unseen\n",
    "\n",
    "# Replace unseen values with a placeholder (optional)\n",
    "season_29_data['Hometown'].replace(-1, label_encoder.transform(['Unknown'])[0], inplace=True)\n",
    "season_29_data['Occupation'].replace(-1, label_encoder.transform(['Unknown'])[0], inplace=True)\n",
    "\n",
    "# Handle Age and Age Difference\n",
    "for col in ['Age', 'Age Difference']:\n",
    "    season_29_data[col] = pd.to_numeric(season_29_data[col], errors='coerce')\n",
    "    season_29_data[col].fillna(season_29_data[col].median(), inplace=True)\n",
    "\n",
    "# Handle unseen labels in 'Place' for Season 29 data\n",
    "season_29_data['Place'] = place_encoder.transform(season_29_data['Place'].astype(str))\n",
    "\n",
    "# For unseen labels in Place, handle them gracefully\n",
    "season_29_data['Place'] = season_29_data['Place'].apply(\n",
    "    lambda x: x if x in place_encoder.classes_ else -1  # Or apply a custom class for unseen labels\n",
    ")\n",
    "\n",
    "# Features for prediction (exclude 'Place' as it's the target we want to predict)\n",
    "X_season_29 = season_29_data[['Age', 'Hometown', 'Occupation', 'Age Difference']]\n",
    "\n",
    "# Predict 'Place' for Season 29 contestants\n",
    "season_29_data['Predicted Place'] = model.predict(X_season_29)\n",
    "\n",
    "# Output the predictions for Season 29 contestants\n",
    "print(season_29_data[['Name', 'Predicted Place']])\n",
    "\n",
    "# Optionally compare predictions to actual labels if available:\n",
    "# print(f\"Accuracy: {accuracy_score(season_29_data['Place'], season_29_data['Predicted Place']):.2f}\")\n",
    "# print(\"Classification Report:\")\n",
    "# print(classification_report(season_29_data['Place'], season_29_data['Predicted Place'], zero_division=1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "343eb3f7",
   "metadata": {},
   "source": [
    "### 4. Final Answer\n",
    "\n",
    "In the first cell seen below, state the name of your predicted winner. \n",
    "In the second cell seen below, justify your prediction using an evaluation technique like RMSE or percent accuracy."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "25533722",
   "metadata": {},
   "source": [
    "#### State the name of your predicted winner here.\n",
    "Zoe McGrady"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e29adde2",
   "metadata": {},
   "source": [
    "#### Justify your prediction here.\n",
    "Using my model, she has the highest prediction, although my model only thinks she'll place third.\n",
    "\n",
    "Attempted steps to up model prediction:\n",
    "Added scoring system instead of attempting to predict the place.\n",
    "Added more data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a60da348",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

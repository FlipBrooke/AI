{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "4f3cc32f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import urllib.parse\n",
    "import csv\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import string\n",
    "\n",
    "embedding_model = SentenceTransformer('paraphrase-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "0498815f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pick_best_definition(word, definitions, sentence):\n",
    "    \"\"\"\n",
    "    Use sentence embeddings to select the definition closest in meaning to the sentence context.\n",
    "    \"\"\"\n",
    "    if not definitions:\n",
    "        return word\n",
    "\n",
    "    sentence_embedding = embedding_model.encode(sentence, convert_to_tensor=True)\n",
    "    definition_embeddings = embedding_model.encode(definitions, convert_to_tensor=True)\n",
    "\n",
    "    cos_scores = util.cos_sim(sentence_embedding, definition_embeddings)[0]\n",
    "    best_idx = cos_scores.argmax().item()\n",
    "    return definitions[best_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "41d7ab33",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_map = {}\n",
    "with open(\"words.csv\", newline='', encoding='utf-8') as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    for row in reader:\n",
    "        if len(row) >= 2:\n",
    "            word_map[row[0].strip()] = row[1].strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "7bf9a1cc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def is_valid_label(label):\n",
    "    \"\"\"\n",
    "    Return True for clean gloss labels: no namespaces, unwanted terms, or citation numbers.\n",
    "    \"\"\"\n",
    "    if not label or label.strip() == '':\n",
    "        return False\n",
    "    invalid_terms = {'infinitive'}\n",
    "    if ':' in label or label.lower() in invalid_terms:\n",
    "        return False\n",
    "    if label.strip().startswith('[') and label.strip().endswith(']'):\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "def strip_punctuation(word):\n",
    "    return word.translate(str.maketrans('', '', string.punctuation))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "6b130d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_definitions_from_ol(ol_tag):\n",
    "    \"\"\"\n",
    "    Collect all valid <a> tags from each <li> in the <ol> under TEXT_SOURCE_LANGUAGE:\n",
    "    - Only consider /wiki/XYZ links without namespaces\n",
    "    - Optionally skip inflection pointers (#TEXT_SOURCE_LANGUAGE) and appendix/etc.\n",
    "    \"\"\"\n",
    "    definitions = []\n",
    "    for li in ol_tag.find_all('li', recursive=False):\n",
    "        # handle any mention spans first\n",
    "        mention = li.find('span', class_='use-with-mention')\n",
    "        if mention:\n",
    "            a = mention.find('a', href=True)\n",
    "            if a and a['href'].startswith('/wiki/'):\n",
    "                href = a['href']\n",
    "                term = href.split('/wiki/')[1].split('#')[0]\n",
    "                if ':' not in term:\n",
    "                    if FILTER_BY_TARGET_LANGUAGE and href.endswith(f'#{TEXT_SOURCE_LANGUAGE}'):\n",
    "                        continue\n",
    "                    title = a.get('title', a.text.strip())\n",
    "                    if is_valid_label(title):\n",
    "                        definitions.append(title)\n",
    "            continue\n",
    "\n",
    "        # then any direct <a> in <li>\n",
    "        for a in li.find_all('a', href=True):\n",
    "            href = a['href']\n",
    "            if not href.startswith('/wiki/'):\n",
    "                continue\n",
    "            term = href.split('/wiki/')[1].split('#')[0]\n",
    "            if ':' in term:\n",
    "                continue\n",
    "            if FILTER_BY_TARGET_LANGUAGE and href.endswith(f'#{TEXT_SOURCE_LANGUAGE}'):\n",
    "                continue\n",
    "            title = a.get('title', a.text.strip())\n",
    "            if is_valid_label(title):\n",
    "                definitions.append(title)\n",
    "\n",
    "    return definitions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "83d515f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_translations(word, delay=1.0):\n",
    "    base_url = f\"https://{TRANSLATION_TARGET_ISO639}.wiktionary.org\"\n",
    "    url = f\"{base_url}/wiki/{urllib.parse.quote(word)}\"\n",
    "    print(f\"[INFO] Fetching page for '{word}': {url}\")\n",
    "\n",
    "    resp = requests.get(url)\n",
    "    if resp.status_code != 200:\n",
    "        print(f\"[ERROR] HTTP {resp.status_code}\")\n",
    "        return []\n",
    "\n",
    "    soup = BeautifulSoup(resp.text, 'html.parser')\n",
    "    lang_h2 = soup.find('h2', id=TEXT_SOURCE_LANGUAGE)\n",
    "    if not lang_h2:\n",
    "        print(f\"[WARN] No {TEXT_SOURCE_LANGUAGE} section for {word}\")\n",
    "        return []\n",
    "\n",
    "    first_ol = lang_h2.find_next('ol')\n",
    "\n",
    "    def find_inflection_link(li):\n",
    "        a = li.find('a', href=lambda x: x and x.startswith('/wiki/') and x.endswith(f'#{TEXT_SOURCE_LANGUAGE}'), recursive=False)\n",
    "        if a:\n",
    "            return a['href']\n",
    "        span = li.find('span', class_='form-of-definition')\n",
    "        if span:\n",
    "            a2 = span.find('a', href=lambda x: x and x.startswith('/wiki/') and x.endswith(f'#{TEXT_SOURCE_LANGUAGE}'))\n",
    "            if a2:\n",
    "                return a2['href']\n",
    "        return None\n",
    "\n",
    "    if first_ol:\n",
    "        first_li = first_ol.find('li', recursive=False)\n",
    "        if first_li:\n",
    "            inf_href = find_inflection_link(first_li)\n",
    "            if inf_href:\n",
    "                base_form_url = f\"{base_url}{inf_href}\"\n",
    "                print(f\"[INFO] Inflection detected: following to base form: {base_form_url}\")\n",
    "                time.sleep(delay)\n",
    "                resp = requests.get(base_form_url)\n",
    "                if resp.status_code == 200:\n",
    "                    soup = BeautifulSoup(resp.text, 'html.parser')\n",
    "                    lang_h2 = soup.find('h2', id=TEXT_SOURCE_LANGUAGE)\n",
    "                    first_ol = lang_h2.find_next('ol') if lang_h2 else None\n",
    "                else:\n",
    "                    print(f\"[WARN] Base form fetch failed: HTTP {resp.status_code}\")\n",
    "\n",
    "    translations = []\n",
    "    pos_tags = ['Particle', 'Conjunction', 'Pronoun', 'Noun', 'Verb', 'Adjective', 'Adverb']\n",
    "    for pos in pos_tags:\n",
    "        span = lang_h2.find_next('span', id=pos)\n",
    "        if not span:\n",
    "            continue\n",
    "        header = span.parent\n",
    "        ol = header.find_next_sibling('ol')\n",
    "        if not ol:\n",
    "            continue\n",
    "        defs = get_definitions_from_ol(ol)\n",
    "        if defs:\n",
    "            translations.extend(defs)\n",
    "\n",
    "    # fallback to first_ol\n",
    "    if not translations and first_ol:\n",
    "        translations = get_definitions_from_ol(first_ol)\n",
    "\n",
    "    # Deduplicate cleanly\n",
    "    result = list(dict.fromkeys(translations))\n",
    "\n",
    "    print(f\"[INFO] Final translations for '{word}': {result}\")\n",
    "    time.sleep(delay)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "784309d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_sentence(sentence):\n",
    "    print(\"=\" * 40)\n",
    "    print(f\"[INFO] Translating: '{sentence}'\")\n",
    "    print(\"=\" * 40)\n",
    "\n",
    "    words = sentence.strip().split()\n",
    "    translated_words = []\n",
    "\n",
    "    for word in words:\n",
    "        original_word = word  # Keep original in case we fallback\n",
    "\n",
    "        if STRIP_PUNCTUATION:\n",
    "            word = strip_punctuation(word)\n",
    "\n",
    "        if word in word_map:\n",
    "            print(f\"[INFO] Found in CSV: '{word}' -> '{word_map[word]}'\")\n",
    "            translation = word_map[word]\n",
    "        else:\n",
    "            lower_matches = [k for k in word_map if k.lower() == word.lower()]\n",
    "            if lower_matches:\n",
    "                match_key = lower_matches[0]\n",
    "                print(f\"[INFO] Case-insensitive match used: '{match_key}' -> '{word_map[match_key]}'\")\n",
    "                translation = word_map[match_key]\n",
    "            else:\n",
    "                defs = fetch_translations(word)\n",
    "                if USE_FIRST_TRANSLATION_ONLY:\n",
    "                    translation = defs[0].split()[0] if defs else original_word\n",
    "                else:\n",
    "                    translation = pick_best_definition(word, defs, sentence) if defs else original_word\n",
    "\n",
    "        translated_words.append(translation)\n",
    "\n",
    "    return \" \".join(translated_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a2470e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "[INFO] Translating: 'hej världen. det här är min översättnings modell'\n",
      "========================================\n",
      "[INFO] Fetching page for 'hej': https://en.wiktionary.org/wiki/hej\n",
      "[INFO] Final translations for 'hej': ['hi', 'hello', 'bye', 'hey']\n",
      "[INFO] Fetching page for 'världen': https://en.wiktionary.org/wiki/v%C3%A4rlden\n",
      "[INFO] Inflection detected: following to base form: https://en.wiktionary.org/wiki/v%C3%A4rld#Swedish\n",
      "[INFO] Final translations for 'världen': ['world', 'the end of the world']\n",
      "[INFO] Fetching page for 'det': https://en.wiktionary.org/wiki/det\n",
      "[INFO] Final translations for 'det': ['it']\n",
      "[INFO] Fetching page for 'här': https://en.wiktionary.org/wiki/h%C3%A4r\n",
      "[INFO] Final translations for 'här': ['here']\n",
      "[INFO] Found in CSV: 'är' -> 'is'\n",
      "[INFO] Fetching page for 'min': https://en.wiktionary.org/wiki/min\n",
      "[INFO] Final translations for 'min': ['minute']\n",
      "[INFO] Fetching page for 'översättnings': https://en.wiktionary.org/wiki/%C3%B6vers%C3%A4ttnings\n",
      "[INFO] Inflection detected: following to base form: https://en.wiktionary.org/wiki/%C3%B6vers%C3%A4ttning#Swedish\n",
      "[INFO] Final translations for 'översättnings': ['translation']\n",
      "[INFO] Fetching page for 'modell': https://en.wiktionary.org/wiki/modell\n",
      "[INFO] Final translations for 'modell': ['model', 'miniature', 'simplification', 'simulation', 'type', 'role model', 'pattern', 'photo']\n",
      "========================================\n",
      "hi world it here is minute translation model\n",
      "========================================\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    USE_FIRST_TRANSLATION_ONLY = True\n",
    "    STRIP_PUNCTUATION = True\n",
    "    FILTER_BY_TARGET_LANGUAGE = True\n",
    "    TEXT_SOURCE_LANGUAGE = \"Swedish\"\n",
    "    TRANSLATION_TARGET_LANGUAGE = \"English\"\n",
    "    TRANSLATION_TARGET_ISO639 = \"en\"\n",
    "\n",
    "    print(\"=\" * 40 + \"\\n\" + translate_sentence(\"\") + \"\\n\" + \"=\" * 40)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82e48c98",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
